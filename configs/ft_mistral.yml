root_dir: '.'
models_dir: 'models/mistral'
dataset: "DATA/Mistral/mistral"
model:
  model_name: "mistral_quantized_8_bit"
  quantized_model_path: "models/mistral/mistral_quantized_8_bit"
  train: True 
  max_tokens: 50
  lora_rank: 32
  lora_layers: 32
  learning_rate: 0.00001
  steps_per_eval: 250
  epochs: 1500
  batch_size: 10
  steps_per_report: 50
  save_every: 50
  seed: 1028
  test: False
  test_adapter_file: 
  temperature: 0.6
  top_p: 0.85
  max_token_len: 50
checkpoint:
  resume: True
  resume_adapter_file: "models/mistral/ft_mistral_quantized_8_bit_2024-04-05_18-58-07/cp_mistral_quantized_8_bit/adapters.npz"
